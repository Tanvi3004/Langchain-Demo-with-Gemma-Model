# Langchain-Demo-with-Gemma-Model

This project demonstrates how to use the Langchain framework with the Gemma model (or any other model supported by Ollama) to create a simple question-answering application. The application is built using Streamlit for the user interface and Langchain for handling the language model interactions. Additionally, LangSmith is integrated for activity tracking, allowing you to monitor and debug your Langchain workflows.

## Prerequisites
Before running the project, ensure you have the following installed:

#### 1.Python 3.7 or higher
#### 2.Ollama - Download and install Ollama from here.
#### 3.LangSmith Account - Sign up for a LangSmith account at LangSmith and obtain your API key for activity tracking.
